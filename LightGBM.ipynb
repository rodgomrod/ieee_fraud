{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "# import modin.pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "import gc\n",
    "import logging\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, TimeSeriesSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import datetime\n",
    "\n",
    "from utils.schemas import *\n",
    "from utils.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_NAME = 'logs/LightGBM.log'\n",
    "logging.basicConfig(filename=LOG_NAME, level=logging.WARNING, format='%(asctime)s %(message)s')\n",
    "logging.warning(\"\")\n",
    "logging.warning(\"##### New LightGBM Model #####\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = pd.read_csv('docs/20190906_PermitationImportance_Rf5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['D1','D10','D11','D12','D13','D14','D15','D2','D3','D4','D5','D6',\n",
    "             'D7','D8','D9','C1','C10','C11','C12','C13','C14','C2','C3','C4','C5','C6','C7','C8','C9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = df_imp[df_imp.Importance > 0].feature.to_list()\n",
    "# X_cols = df_imp.feature[:100].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f289c4252c6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_cols' is not defined"
     ]
    }
   ],
   "source": [
    "len(X_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R1', 'V258', 'C7', 'V45', 'C1', 'C12', 'C8', 'C4', 'V257']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cols[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "id1 = ['addr1', 'addr2', 'card1', 'day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2 = ['card1', 'card2', 'card3', 'card5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['addr1', 'addr2', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = id2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv(data_folder+'/train_syn_ft_eng_1.csv', dtype = schema_synthetic_ft_eng_1, usecols=list(set(X_cols+['isFraud']+id_cols)))\n",
    "# test = pd.read_csv(data_folder+'/test_syn_ft_eng_1.csv', dtype = schema_synthetic_ft_eng_1, usecols=list(set(X_cols+['isFraud']+id_cols)))\n",
    "train = pd.read_csv(data_folder+'/train_ft_eng_1.csv', dtype = schema_ft_eng_1).sort_values('TransactionDT', ascending=True)\n",
    "test = pd.read_csv(data_folder+'/test_ft_eng_1.csv', dtype = schema_ft_eng_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9025, 677)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_1 = train[train.isFraud == 1]\n",
    "# train_1.shape\n",
    "\n",
    "# train_0 = train[train.isFraud == 0].sample(train_1.shape[0]*3, random_state=42)\n",
    "\n",
    "# mini_train = pd.concat([train_1, train_0], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['day'] = np.floor((train['TransactionDT'] / (3600 * 24) - 1))\n",
    "test['day'] = np.floor((test['TransactionDT'] / (3600 * 24) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = train.groupby(group_cols).grouper.group_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_dict = dict()\n",
    "for c in X_cols:\n",
    "    if c not in cat_ft:\n",
    "        imp_dict[c] = train[c].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = [x for x in train.columns if x not in ['isFraud', 'TransactionDT', 'device_name', 'device_version']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = [x for x in X_cols if x not in ['day']+id_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_cols = [x for x in X_cols if x not in ['P_emaildomain_0', 'device_version_fe1', 'N17', 'N9', 'R_emaildomain_0', 'device_name_fe1', 'N7', 'R_emaildomain_1', 'N22', 'N10', 'N12', 'R_emaildomain_0_fe1', 'P_emaildomain_0_fe1', 'proc_id_30_0_fe1', 'N13', 'R_emaildomain_1_fe1', 'R_emaildomain_1_fe2', 'P_emaildomain_0_fe2', 'N21', 'proc_id_30_1_fe1', 'proc_id_31_0_fe1', 'proc_id_31_0_fe2', 'device_name', 'device_version']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[X_cols]#.fillna(imp_dict)\n",
    "y = train.isFraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[X_cols]\n",
    "y_test = test.isFraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.warning(\"Used columns: {}\".format(X_cols))\n",
    "k = 5\n",
    "logging.warning(\"Folds number: {}\".format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_kfold = GroupKFold(n_splits=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = X.index\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_leaves': 256,\n",
    "    'max_depth': 15,\n",
    "    'max_leaf_nodes': 45,\n",
    "    'min_sample_leaf': 20,\n",
    "    'metric': ['AUC'],\n",
    "    'first_metric_only': True,\n",
    "    'n_estimators': 20000,\n",
    "    'num_threads': 8,\n",
    "    'learning_rate': 0.01,\n",
    "    'colsample_bytree': 0.3,\n",
    "    'objective': 'xentropy',\n",
    "    'n_jobs': -1,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 5,\n",
    "    'importance_type': 'gain',\n",
    "#     'lambda_l1': 0.05,\n",
    "#     'lambda_l2': 0.05,\n",
    "    'bagging_seed': 42,\n",
    "    'random_state':42,\n",
    "    'seed': 42,\n",
    "    'feature_fraction_seed': 42,\n",
    "    'drop_seed': 42,\n",
    "    'data_random_seed': 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.warning(\"Searching best max_depth\")\n",
    "\n",
    "# for train_index, test_index in group_kfold.split(X, y, groups):\n",
    "#     X_fit, X_val = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "#     y_fit, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# scores_dict = dict()\n",
    "# for i in range(5, 20):\n",
    "#     print('Max depth = {}'.format(i))\n",
    "#     logging.warning('Max depth = {}'.format(i))\n",
    "#     params['max_depth'] = i\n",
    "#     lgb_model = lgb.LGBMClassifier(**params)\n",
    "#     lgb_model.fit(X_fit,\n",
    "#                   y_fit,\n",
    "#                   eval_set=[(X_val, y_val), (X_fit, y_fit)],\n",
    "#                   verbose=100,\n",
    "#                   early_stopping_rounds=40)\n",
    "#     scores_dict[i] = lgb_model.best_score_['valid_0']['auc']\n",
    "\n",
    "# b = pd.DataFrame({'Depth': [x for x in scores_dict.keys()], 'AUC': [x for x in scores_dict.values()]})\n",
    "# md = b[b.AUC == b.AUC.max()].Depth\n",
    "# md.values[0]\n",
    "\n",
    "# params['max_depth'] = md.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb_model = lgb.LGBMClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.warning(\"Params: {}\".format(str(lgb_model.get_params())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_test = test.groupby(group_cols).grouper.group_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_strategy_skf = skf.split(train_ids, y)\n",
    "fold_strategy_gkf = group_kfold.split(X, y, groups)\n",
    "fold_strategy_tss = tscv.split(X=X, y=y)\n",
    "\n",
    "# fold_strategy_test = group_kfold.split(X_test, y_test, groups_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(fold_strategy):\n",
    "    lgb_model = lgb.LGBMClassifier(**params)\n",
    "    logging.warning(\"Params: {}\".format(str(lgb_model.get_params())))\n",
    "    counter = 1\n",
    "    auc_score = 0\n",
    "    iterat = 0\n",
    "    list_iter = list()\n",
    "    y_preds = np.zeros(X_test.shape[0])\n",
    "    importances = np.zeros(X_test.shape[1])\n",
    "\n",
    "    for train_index, test_index in fold_strategy:\n",
    "        print('Fold {}'.format(counter))\n",
    "        logging.warning(\"Training fold {}\".format(counter))\n",
    "\n",
    "        X_fit, X_val = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "        y_fit, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        lgb_model.fit(X_fit,\n",
    "                      y_fit,\n",
    "    #                   eval_set=[(X_val, y_val), (X_fit, y_fit)],\n",
    "                      eval_set=[(X_val, y_val)],\n",
    "                      verbose=200,\n",
    "                      early_stopping_rounds=40)\n",
    "\n",
    "        logging.warning(\"Best AUC in this fold: {}\".format(lgb_model.best_score_['valid_0']['auc']))\n",
    "        logging.warning(\"Best iteration in this fold: {}\".format(lgb_model.best_iteration_))\n",
    "        auc_score += lgb_model.best_score_['valid_0']['auc']\n",
    "        it = lgb_model.best_iteration_\n",
    "        iterat += it\n",
    "        list_iter.append(it)\n",
    "        importances += lgb_model.feature_importances_/k\n",
    "        predictions = lgb_model.predict_proba(X_test)[:,1]\n",
    "        predictions = scaler.fit_transform(predictions.reshape(-1, 1))\n",
    "        \n",
    "        print(predictions)\n",
    "        y_preds += predictions/k\n",
    "\n",
    "\n",
    "        del X_fit\n",
    "        del X_val\n",
    "        del y_fit\n",
    "        del y_val\n",
    "        del train_index\n",
    "        del test_index\n",
    "        gc.collect()\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "    mean_auc_score = auc_score/k\n",
    "    mean_iterat = iterat/k\n",
    "\n",
    "    logging.warning(\"Mean AUC in {0} folds: {1}\".format(k, mean_auc_score))\n",
    "    logging.warning(\"Mean iterations in {0} folds: {1}\".format(k, mean_iterat))\n",
    "    \n",
    "    return y_preds, importances, mean_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with GoupKFold\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 40 rounds.\n",
      "[200]\tvalid_0's auc: 0.890897\n",
      "[400]\tvalid_0's auc: 0.897953\n",
      "[600]\tvalid_0's auc: 0.900727\n",
      "[800]\tvalid_0's auc: 0.902077\n",
      "Early stopping, best iteration is:\n",
      "[788]\tvalid_0's auc: 0.902234\n",
      "[0.00234367 0.00463863 0.00515222 ... 0.00587624 0.00838218 0.00421996]\n",
      "[0.00194122]\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 40 rounds.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/errodringer/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-69-124e3abf5162>\", line 2, in <module>\n",
      "    y_preds_gkf, importances_gkf, mean_auc_score_gkf = make_predictions(fold_strategy_gkf)\n",
      "  File \"<ipython-input-68-de581a83437f>\", line 23, in make_predictions\n",
      "    early_stopping_rounds=40)\n",
      "  File \"/home/errodringer/.local/lib/python3.6/site-packages/lightgbm/sklearn.py\", line 744, in fit\n",
      "    callbacks=callbacks)\n",
      "  File \"/home/errodringer/.local/lib/python3.6/site-packages/lightgbm/sklearn.py\", line 544, in fit\n",
      "    callbacks=callbacks)\n",
      "  File \"/home/errodringer/.local/lib/python3.6/site-packages/lightgbm/engine.py\", line 218, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"/home/errodringer/.local/lib/python3.6/site-packages/lightgbm/basic.py\", line 1802, in update\n",
      "    ctypes.byref(is_finished)))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/errodringer/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/errodringer/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/errodringer/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/errodringer/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 71, in ismodule\n",
      "    return isinstance(object, types.ModuleType)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "print('Training with GoupKFold')\n",
    "y_preds_gkf, importances_gkf, mean_auc_score_gkf = make_predictions(fold_strategy_gkf)\n",
    "# print('')\n",
    "# print('Training with TimeSeriesSplit')\n",
    "# y_preds_tss, importances_tss, mean_auc_score_tss = make_predictions(fold_strategy_tss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.60861721e-04, 8.87967391e-01, 5.76581348e-03, 6.85511785e-03,\n",
       "       4.47044572e-04, 8.91869979e-03, 1.04121164e-03, 1.10320476e-03,\n",
       "       1.27414391e-03, 3.76506777e-03])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_gkf[230:240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00198887, 0.82300609, 0.0099255 , 0.00670942, 0.00139805,\n",
       "       0.01039156, 0.00334991, 0.00273602, 0.00340318, 0.00745082])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_tss[230:240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_final = (y_preds_gkf + y_preds_tss) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.read_csv(data_folder+'/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['isFraud'] = y_preds_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3663549</td>\n",
       "      <td>0.000519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3663550</td>\n",
       "      <td>0.003001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3663551</td>\n",
       "      <td>0.000802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3663552</td>\n",
       "      <td>0.002013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3663553</td>\n",
       "      <td>0.001086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID   isFraud\n",
       "0        3663549  0.000519\n",
       "1        3663550  0.003001\n",
       "2        3663551  0.000802\n",
       "3        3663552  0.002013\n",
       "4        3663553  0.001086"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.date.today()\n",
    "D = today.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_name = '{0}_LightGBM_{1}'.format(D, round(mean_auc_score_gkf, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20190908_LightGBM_0.95941'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.warning(\"Submission name: {}\".format(submission_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('submissions/{}.csv'.format(submission_name), sep=',', header=True, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.warning(\"End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 40 rounds.\n",
      "[200]\tvalid_0's auc: 0.952958\n",
      "[400]\tvalid_0's auc: 0.958528\n",
      "Early stopping, best iteration is:\n",
      "[530]\tvalid_0's auc: 0.959233\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 40 rounds.\n",
      "[200]\tvalid_0's auc: 0.947061\n",
      "[400]\tvalid_0's auc: 0.952863\n",
      "[600]\tvalid_0's auc: 0.953964\n",
      "Early stopping, best iteration is:\n",
      "[637]\tvalid_0's auc: 0.954343\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 40 rounds.\n",
      "[200]\tvalid_0's auc: 0.954049\n",
      "[400]\tvalid_0's auc: 0.958746\n",
      "[600]\tvalid_0's auc: 0.959474\n",
      "Early stopping, best iteration is:\n",
      "[578]\tvalid_0's auc: 0.959689\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 40 rounds.\n",
      "[200]\tvalid_0's auc: 0.951073\n",
      "[400]\tvalid_0's auc: 0.955019\n",
      "[600]\tvalid_0's auc: 0.956798\n",
      "Early stopping, best iteration is:\n",
      "[604]\tvalid_0's auc: 0.956889\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 40 rounds.\n",
      "[200]\tvalid_0's auc: 0.948491\n",
      "[400]\tvalid_0's auc: 0.953397\n",
      "[600]\tvalid_0's auc: 0.95452\n",
      "Early stopping, best iteration is:\n",
      "[671]\tvalid_0's auc: 0.955083\n",
      "Fold 6\n",
      "Training until validation scores don't improve for 40 rounds.\n",
      "[200]\tvalid_0's auc: 0.950828\n",
      "[400]\tvalid_0's auc: 0.955203\n",
      "[600]\tvalid_0's auc: 0.956776\n",
      "Early stopping, best iteration is:\n",
      "[564]\tvalid_0's auc: 0.956891\n",
      "Fold 7\n",
      "Training until validation scores don't improve for 40 rounds.\n",
      "[200]\tvalid_0's auc: 0.957415\n",
      "[400]\tvalid_0's auc: 0.961953\n",
      "[600]\tvalid_0's auc: 0.963541\n",
      "Early stopping, best iteration is:\n",
      "[652]\tvalid_0's auc: 0.963997\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "auc_score = 0\n",
    "iterat = 0\n",
    "list_iter = list()\n",
    "y_preds = np.zeros(X_test.shape[0])\n",
    "importances = np.zeros(X_test.shape[1])\n",
    "\n",
    "for train_index, test_index in fold_strategy:\n",
    "    print('Fold {}'.format(counter))\n",
    "    logging.warning(\"Training fold {}\".format(counter))\n",
    "\n",
    "    X_fit, X_val = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    y_fit, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    lgb_model.fit(X_fit,\n",
    "                  y_fit,\n",
    "#                   eval_set=[(X_val, y_val), (X_fit, y_fit)],\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  verbose=200,\n",
    "                  early_stopping_rounds=40)\n",
    "    \n",
    "    logging.warning(\"Best AUC in this fold: {}\".format(lgb_model.best_score_['valid_0']['auc']))\n",
    "    logging.warning(\"Best iteration in this fold: {}\".format(lgb_model.best_iteration_))\n",
    "    auc_score += lgb_model.best_score_['valid_0']['auc']\n",
    "#     lgb_model.predict_proba(test[X.columns])\n",
    "#     preds = lgb_model.predict_proba(X_test[X.columns])[:,1]\n",
    "#     preds = lgb_model.predict_proba(X_fit_test[X.columns])[:,1]\n",
    "#     print('AUC test score: {}\\n'.format(roc_auc_score(y_fit_test, preds)))\n",
    "#     print('AUC 20% test score: {}'.format(roc_auc_score(y_test[:int(len(y_test)*0.2)],\n",
    "#                                                         preds[:int(len(y_test)*0.2)])))\n",
    "#     print('AUC 80% test score: {}'.format(roc_auc_score(y_test[int(len(y_test)*0.2):],\n",
    "#                                                         preds[int(len(y_test)*0.2):])))\n",
    "    it = lgb_model.best_iteration_\n",
    "    iterat += it\n",
    "    list_iter.append(it)\n",
    "    importances += lgb_model.feature_importances_/k\n",
    "    y_preds += lgb_model.predict_proba(X_test)[:,1]/k\n",
    "\n",
    "\n",
    "    del X_fit\n",
    "    del X_val\n",
    "    del y_fit\n",
    "    del y_val\n",
    "    del train_index\n",
    "    del test_index\n",
    "    gc.collect()\n",
    "    \n",
    "    counter += 1\n",
    "\n",
    "    \n",
    "mean_auc_score = auc_score/k\n",
    "mean_iterat = iterat/k\n",
    "\n",
    "logging.warning(\"Mean AUC in {0} folds: {1}\".format(k, mean_auc_score))\n",
    "logging.warning(\"Mean iterations in {0} folds: {1}\".format(k, mean_iterat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>R1</td>\n",
       "      <td>91065.925002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>V257</td>\n",
       "      <td>50031.108368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>N3</td>\n",
       "      <td>26082.882709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>R12</td>\n",
       "      <td>24254.089073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>R4</td>\n",
       "      <td>20582.440879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>N6</td>\n",
       "      <td>20300.030602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>R11</td>\n",
       "      <td>18503.751742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>card2_fe1</td>\n",
       "      <td>17764.991037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>TransactionAmt</td>\n",
       "      <td>17752.117065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>V294</td>\n",
       "      <td>17534.175283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>R7</td>\n",
       "      <td>17030.447100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>N1</td>\n",
       "      <td>16827.202808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>N5</td>\n",
       "      <td>15593.731761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>R9</td>\n",
       "      <td>15504.610400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>R28</td>\n",
       "      <td>14613.813548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>R3</td>\n",
       "      <td>14444.067987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>R29</td>\n",
       "      <td>14007.975708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>card1_fe1</td>\n",
       "      <td>13971.570393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>R8</td>\n",
       "      <td>13417.728702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>R5</td>\n",
       "      <td>13373.204705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature    importance\n",
       "0               R1  91065.925002\n",
       "1             V257  50031.108368\n",
       "2               N3  26082.882709\n",
       "3              R12  24254.089073\n",
       "4               R4  20582.440879\n",
       "5               N6  20300.030602\n",
       "6              R11  18503.751742\n",
       "7        card2_fe1  17764.991037\n",
       "8   TransactionAmt  17752.117065\n",
       "9             V294  17534.175283\n",
       "10              R7  17030.447100\n",
       "11              N1  16827.202808\n",
       "12              N5  15593.731761\n",
       "13              R9  15504.610400\n",
       "14             R28  14613.813548\n",
       "15              R3  14444.067987\n",
       "16             R29  14007.975708\n",
       "17       card1_fe1  13971.570393\n",
       "18              R8  13417.728702\n",
       "19              R5  13373.204705"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_importaces = pd.DataFrame({'feature': X.columns, 'importance': importances})\\\n",
    ".sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "# df_importaces['cs'] = df_importaces.importance.cumsum()\n",
    "# # df_importaces.cs = df_importaces.cs/df_importaces.cs.max()\n",
    "# df_importaces.importance = df_importaces.importance/df_imp.cs\n",
    "df_importaces.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.read_csv(data_folder+'/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['isFraud'] = y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3663549</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3663550</td>\n",
       "      <td>0.002492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3663551</td>\n",
       "      <td>0.000582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3663552</td>\n",
       "      <td>0.000902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3663553</td>\n",
       "      <td>0.000977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID   isFraud\n",
       "0        3663549  0.000247\n",
       "1        3663550  0.002492\n",
       "2        3663551  0.000582\n",
       "3        3663552  0.000902\n",
       "4        3663553  0.000977"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.date.today()\n",
    "D = today.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_name = '{0}_LightGBM_{1}'.format(D, round(mean_auc_score, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20190908_LightGBM_0.958018'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.warning(\"Submission name: {}\".format(submission_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('submissions/{}.csv'.format(submission_name), sep=',', header=True, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.warning(\"End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_groups = new_X.groupby(group_cols).grouper.group_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.895268\tvalid_0's auc: 0.880426\n",
      "[200]\ttraining's auc: 0.930704\tvalid_0's auc: 0.882666\n",
      "Early stopping, best iteration is:\n",
      "[173]\ttraining's auc: 0.923412\tvalid_0's auc: 0.883409\n",
      "AUC test score: 0.864554651319306\n",
      "AUC 20% test score: 0.8795648576345201\n",
      "AUC 80% test score: 0.8593868240892053\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "auc_score = 0\n",
    "iterat = 0\n",
    "list_iter = list()\n",
    "# for train_index, test_index in skf.split(train_ids, y):\n",
    "for train_index, test_index in group_kfold.split(new_X, new_y, new_groups):\n",
    "# for train_index, test_index in tscv.split(X=X, y=y):\n",
    "    print('Fold {}\\n'.format(counter))\n",
    "    logging.warning(\"Training fold {}\".format(counter))\n",
    "\n",
    "    X_fit, X_val = new_X.iloc[train_index, :], new_X.iloc[test_index, :]\n",
    "    y_fit, y_val = new_y.iloc[train_index], new_y.iloc[test_index]\n",
    "\n",
    "    lgb_model.fit(X_fit,\n",
    "                  y_fit,\n",
    "                  eval_set=[(X_val, y_val), (X_fit, y_fit)],\n",
    "                  verbose=100,\n",
    "                  early_stopping_rounds=100)\n",
    "    \n",
    "    logging.warning(\"Best AUC in this fold: {}\".format(lgb_model.best_score_['valid_0']['auc']))\n",
    "    logging.warning(\"Best iteration in this fold: {}\".format(lgb_model.best_iteration_))\n",
    "    auc_score += lgb_model.best_score_['valid_0']['auc']\n",
    "    preds = lgb_model.predict_proba(X_test[X.columns])[:,1]\n",
    "    print('AUC test score: {}'.format(roc_auc_score(y_test, preds)))\n",
    "    print('AUC 20% test score: {}'.format(roc_auc_score(y_test[:int(len(y_test)*0.2)],\n",
    "                                                        preds[:int(len(y_test)*0.2)])))\n",
    "    print('AUC 80% test score: {}'.format(roc_auc_score(y_test[int(len(y_test)*0.2):],\n",
    "                                                        preds[int(len(y_test)*0.2):])))\n",
    "    it = lgb_model.best_iteration_\n",
    "    iterat += it\n",
    "    list_iter.append(it)\n",
    "\n",
    "    del X_fit\n",
    "    del X_val\n",
    "    del y_fit\n",
    "    del y_val\n",
    "    del train_index\n",
    "    del test_index\n",
    "    gc.collect()\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "    break\n",
    "    \n",
    "mean_auc_score = auc_score/k\n",
    "mean_iterat = iterat/k\n",
    "\n",
    "logging.warning(\"Mean AUC in {0} folds: {1}\".format(k, mean_auc_score))\n",
    "logging.warning(\"Mean iterations in {0} folds: {1}\".format(k, mean_iterat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2624.6"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_iterat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2624"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['n_estimators'] = int(mean_iterat)\n",
    "params['n_estimators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.7, bagging_freq=2, bagging_seed=42,\n",
       "               boosting_type='gbdt', class_weight=None, colsample_bytree=0.3,\n",
       "               data_random_seed=42, drop_seed=42, feature_fraction_seed=42,\n",
       "               first_metric_only=True, importance_type='split', lambda_l1=0,\n",
       "               lambda_l2=0, learning_rate=0.01, max_depth=-1, metric=['AUC'],\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=2624, n_jobs=-1, num_leaves=311, num_threads=64,\n",
       "               objective='xentropy', random_state=42, reg_alpha=0.0,\n",
       "               reg_lambda=0.0, seed=42, silent=True, subsample=1.0, ...)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model = lgb.LGBMClassifier(**params)\n",
    "lgb_model.fit(train[X_cols+drop_cols], train.isFraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = lgb_model.predict_proba(test[X.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.read_csv(data_folder+'/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['isFraud'] = y_preds[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3663549</td>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3663550</td>\n",
       "      <td>0.000302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3663551</td>\n",
       "      <td>0.000472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3663552</td>\n",
       "      <td>0.000826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3663553</td>\n",
       "      <td>0.000374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID   isFraud\n",
       "0        3663549  0.000113\n",
       "1        3663550  0.000302\n",
       "2        3663551  0.000472\n",
       "3        3663552  0.000826\n",
       "4        3663553  0.000374"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.date.today()\n",
    "D = today.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_name = '{0}_LightGBM_{1}'.format(D, mean_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20190903_LightGBM_0.9732650305281695'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.warning(\"Submission name: {}\".format(submission_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('submissions/{}.csv'.format(submission_name), sep=',', header=True, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.warning(\"End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5084, 2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub[df_sub.isFraud>0.9].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
