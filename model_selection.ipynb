{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "import gc\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.schemas import *\n",
    "from utils.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_folder+'/train_ft_eng_0.csv', dtype = schema_generated_0)\n",
    "test = pd.read_csv(data_folder+'/test_ft_eng_0.csv', dtype = schema_generated_0)\n",
    "df_imp = pd.read_csv('docs/ft_importances_20190811.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TransactionAmt</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>card1</td>\n",
       "      <td>2.204488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C13</td>\n",
       "      <td>2.070567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N1</td>\n",
       "      <td>1.881225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C1</td>\n",
       "      <td>1.691782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature  importance\n",
       "0  TransactionAmt    3.000000\n",
       "1           card1    2.204488\n",
       "2             C13    2.070567\n",
       "3              N1    1.881225\n",
       "4              C1    1.691782"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imp = pd.read_csv('docs/ft_importances_20190811.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = df_imp[df_imp.importance > 0.1].feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_train = train.sample(120000, random_state = 42).fillna(train.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mini_train.sort_values('TransactionDT')[X_cols]\n",
    "y = mini_train.sort_values('TransactionDT').isFraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = X.iloc[:int(X.shape[0]*0.8), :]\n",
    "X_test = X.iloc[int(X.shape[0]*0.8):, :]\n",
    "y_train = y[:int(X.shape[0]*0.8)]\n",
    "y_test = y[int(X.shape[0]*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize max_depth\n",
    "params = {\n",
    "    'num_leaves': 491,\n",
    "    'metric': ['AUC'],\n",
    "    'first_metric_only': True,\n",
    "    'n_estimators': 20000,\n",
    "    'learning_rate': 0.008,\n",
    "    'colsample_bytree': 0.85,\n",
    "    'objective': 'xentropy',\n",
    "    'n_jobs': -1,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'lambda_l1': 0,\n",
    "    'lambda_l2': 0,\n",
    "    'bagging_seed': 42,\n",
    "    'seed': 42,\n",
    "    'feature_fraction_seed': 42,\n",
    "    'drop_seed': 42,\n",
    "    'data_random_seed': 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0.001, 0.05, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_Depth: 21\n",
      "Training until validation scores don't improve for 40 rounds.\n",
      "[100]\tvalid_0's auc: 0.892142\n",
      "[200]\tvalid_0's auc: 0.895234\n",
      "[300]\tvalid_0's auc: 0.89865\n",
      "Early stopping, best iteration is:\n",
      "[328]\tvalid_0's auc: 0.900333\n",
      "\n",
      "\n",
      "Max_Depth: 22\n",
      "Training until validation scores don't improve for 40 rounds.\n",
      "[100]\tvalid_0's auc: 0.8933\n",
      "[200]\tvalid_0's auc: 0.897393\n",
      "[300]\tvalid_0's auc: 0.901701\n",
      "Early stopping, best iteration is:\n",
      "[311]\tvalid_0's auc: 0.902474\n",
      "\n",
      "\n",
      "Max_Depth: 23\n",
      "Training until validation scores don't improve for 40 rounds.\n",
      "[100]\tvalid_0's auc: 0.890424\n",
      "[200]\tvalid_0's auc: 0.897478\n",
      "[300]\tvalid_0's auc: 0.898031\n",
      "Early stopping, best iteration is:\n",
      "[265]\tvalid_0's auc: 0.898698\n",
      "\n",
      "\n",
      "Max_Depth: 24\n",
      "Training until validation scores don't improve for 40 rounds.\n",
      "[100]\tvalid_0's auc: 0.894404\n",
      "[200]\tvalid_0's auc: 0.897921\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's auc: 0.898709\n",
      "\n",
      "\n",
      "Max_Depth: 25\n",
      "Training until validation scores don't improve for 40 rounds.\n",
      "[100]\tvalid_0's auc: 0.896674\n",
      "[200]\tvalid_0's auc: 0.903463\n",
      "Early stopping, best iteration is:\n",
      "[200]\tvalid_0's auc: 0.903463\n",
      "\n",
      "\n",
      "Max_Depth: 26\n",
      "Training until validation scores don't improve for 40 rounds.\n",
      "[100]\tvalid_0's auc: 0.895048\n",
      "[200]\tvalid_0's auc: 0.902083\n",
      "Early stopping, best iteration is:\n",
      "[214]\tvalid_0's auc: 0.902797\n",
      "\n",
      "\n",
      "Max_Depth: 27\n",
      "Training until validation scores don't improve for 40 rounds.\n",
      "[100]\tvalid_0's auc: 0.895796\n",
      "[200]\tvalid_0's auc: 0.901056\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's auc: 0.901432\n",
      "\n",
      "\n",
      "Max_Depth: 28\n",
      "Training until validation scores don't improve for 40 rounds.\n",
      "[100]\tvalid_0's auc: 0.894183\n",
      "[200]\tvalid_0's auc: 0.900337\n",
      "[300]\tvalid_0's auc: 0.900933\n",
      "Early stopping, best iteration is:\n",
      "[331]\tvalid_0's auc: 0.902125\n",
      "\n",
      "\n",
      "Max_Depth: 29\n",
      "Training until validation scores don't improve for 40 rounds.\n",
      "[100]\tvalid_0's auc: 0.895227\n",
      "[200]\tvalid_0's auc: 0.902492\n",
      "[300]\tvalid_0's auc: 0.901685\n",
      "Early stopping, best iteration is:\n",
      "[268]\tvalid_0's auc: 0.903404\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25</td>\n",
       "      <td>0.903463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>29</td>\n",
       "      <td>0.903404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26</td>\n",
       "      <td>0.902797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>22</td>\n",
       "      <td>0.902474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>28</td>\n",
       "      <td>0.902125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    depth       auc\n",
       "18     25  0.903463\n",
       "22     29  0.903404\n",
       "19     26  0.902797\n",
       "15     22  0.902474\n",
       "21     28  0.902125"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max_depth_list = list(range(7, 21))\n",
    "# aucs_list = list()\n",
    "# depth_list = list()\n",
    "max_depth_list = list(range(21, 30))\n",
    "for max_depth in max_depth_list:\n",
    "    print('Max_Depth:', max_depth)\n",
    "    params['max_depth'] = max_depth\n",
    "    lgb_model = lgb.LGBMClassifier(**params)\n",
    "    lgb_model.fit(X_train,\n",
    "                   y_train,\n",
    "                   eval_set=[(X_test, y_test)],\n",
    "                   verbose=100,\n",
    "                   early_stopping_rounds=40,\n",
    "#                    eval_metric=custom_loss\n",
    "                  )\n",
    "    depth_list.append(max_depth)\n",
    "    aucs_list.append(roc_auc_score(y_test, lgb_model.predict_proba(X_test)[:,1]))\n",
    "    print('\\n')\n",
    "    \n",
    "df_depth = pd.DataFrame({'depth': depth_list, 'auc': aucs_list}).sort_values('auc', ascending = False)\n",
    "df_depth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize max_depth\n",
    "params = {\n",
    "    'num_leaves': 491,\n",
    "    'max_depth': 25,\n",
    "    'metric': ['AUC'],\n",
    "    'first_metric_only': True,\n",
    "    'n_estimators': 20000,\n",
    "    'learning_rate': 0.008,\n",
    "    'colsample_bytree': 0.85,\n",
    "    'objective': 'xentropy',\n",
    "    'n_jobs': -1,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'lambda_l1': 0,\n",
    "    'lambda_l2': 0,\n",
    "    'bagging_seed': 42,\n",
    "    'seed': 42,\n",
    "    'feature_fraction_seed': 42,\n",
    "    'drop_seed': 42,\n",
    "    'data_random_seed': 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009,\n",
       "       0.01 , 0.011, 0.012, 0.013, 0.014, 0.015, 0.016, 0.017, 0.018,\n",
       "       0.019, 0.02 , 0.021, 0.022, 0.023, 0.024, 0.025, 0.026, 0.027,\n",
       "       0.028, 0.029, 0.03 , 0.031, 0.032, 0.033, 0.034, 0.035, 0.036,\n",
       "       0.037, 0.038, 0.039, 0.04 , 0.041, 0.042, 0.043, 0.044, 0.045,\n",
       "       0.046, 0.047, 0.048, 0.049])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0.001, 0.05, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 40 rounds.\n",
      "[100]\tvalid_0's auc: 0.880895\n",
      "[200]\tvalid_0's auc: 0.889505\n",
      "[300]\tvalid_0's auc: 0.894199\n",
      "[400]\tvalid_0's auc: 0.897251\n",
      "[500]\tvalid_0's auc: 0.899565\n",
      "[600]\tvalid_0's auc: 0.901131\n",
      "Early stopping, best iteration is:\n",
      "[645]\tvalid_0's auc: 0.901972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, bagging_seed=42,\n",
       "               boosting_type='gbdt', class_weight=None, colsample_bytree=0.85,\n",
       "               data_random_seed=42, drop_seed=42, feature_fraction_seed=42,\n",
       "               first_metric_only=True, importance_type='split', lambda_l1=0,\n",
       "               lambda_l2=0, learning_rate=0.008, max_depth=25, metric=['AUC'],\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=20000, n_jobs=-1, num_leaves=491,\n",
       "               objective='xentropy', random_state=None, reg_alpha=0.0,\n",
       "               reg_lambda=0.0, seed=42, silent=True, subsample=1.0,\n",
       "               subsample_for_bin=200000, ...)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model = lgb.LGBMClassifier(**params)\n",
    "lgb_model.fit(X_train,\n",
    "               y_train,\n",
    "               eval_set=[(X_test, y_test)],\n",
    "               verbose=100,\n",
    "               early_stopping_rounds=40,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model.best_iteration_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1257"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['n_estimators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['n_estimators'] = int(967*1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, bagging_seed=42,\n",
       "               boosting_type='gbdt', class_weight=None, colsample_bytree=0.85,\n",
       "               data_random_seed=42, drop_seed=42, feature_fraction_seed=42,\n",
       "               first_metric_only=True, importance_type='split', lambda_l1=0,\n",
       "               lambda_l2=0, learning_rate=0.008, max_depth=25, metric=['AUC'],\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=1257, n_jobs=-1, num_leaves=491,\n",
       "               objective='xentropy', random_state=None, reg_alpha=0.0,\n",
       "               reg_lambda=0.0, seed=42, silent=True, subsample=1.0,\n",
       "               subsample_for_bin=200000, ...)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model = lgb.LGBMClassifier(**params)\n",
    "lgb_model.fit(train[X_cols], train.isFraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = lgb_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.read_csv(data_folder+'/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['isFraud'] = y_preds[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('submissions/benchmark_ft_selection_ft_eng_0_1257_rounds.csv', sep=',', header=True, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
